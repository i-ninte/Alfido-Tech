# -*- coding: utf-8 -*-
"""weather.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LFsOEpb7YRdgamXhdyXXN1m8ywKojXLk

## IMPORTING LIBRARIES
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""## READING THE DATASET"""

df = pd.read_csv("weather.csv")

"""#PREVIEWING THE FIRST 5 ROWS"""

df.head()

"""## CHECKING FOR ERRORS"""

df.isnull().sum()

"""#GENERAL INFO AND STATS OF THE DATASET"""

df.info()

df.describe()

"""## CHECKING THE NUMBER OF ENTERIES"""

df.shape

"""## COLUMN NAMES"""

df.columns

"""## CHECKING FOR DUPLICATES"""

# Check for duplicate rows based on all columns
duplicates = df[df.duplicated()]


if not duplicates.empty:
    print("Duplicate Rows except first occurrence:")
    print(duplicates)
else:
    print("No duplicate rows found.")

"""#ANALYSES

## TEMPERATURE ANALYSIS
"""

import matplotlib.pyplot as plt
import seaborn as sns

df['Date/Time'] = pd.to_datetime(df['Date/Time'])

# Set the 'Date/Time' column as the index
df.set_index('Date/Time', inplace=True)

# Plotting
plt.figure(figsize=(12, 6))
sns.lineplot(data=df['Temp_C'], color='blue')
plt.title('Temperature Distribution Over Time')
plt.xlabel('Date/Time')
plt.ylabel('Temperature (°C)')
plt.grid(True)
plt.show()

"""It appears that the initial three months of 2012 experienced notably cold temperatures, followed by a gradual and consistent rise in temperature from March to September. Notably, September stands out as a month with the highest increase in temperature. As the year progresses into the last three months, a return to colder temperatures is observed.

## CALCULATING THE AVERAGE TEMPERATURE OF EACH QUARTER
"""

df['Date/Time'] = pd.to_datetime(df['Date/Time'])

df.set_index('Date/Time', inplace=True)

# Resample the data into quarters and calculate the mean temperature for each quarter
average_temperatures = df['Temp_C'].resample('Q').mean()

# Print the average temperatures for each quarter
print("Average Temperatures for Each Quarter:")
print(average_temperatures)

import matplotlib.pyplot as plt
import seaborn as sns

df['Date/Time'] = pd.to_datetime(df['Date/Time'])

# Set the 'Date/Time' column as the index
df.set_index('Date/Time', inplace=True)

# Resample the data into quarters and calculate the mean temperature for each quarter
df_quarters = df['Temp_C'].resample('Q').mean()

# Plotting
plt.figure(figsize=(12, 6))
sns.barplot(x=df_quarters.index, y=df_quarters, color='orange')
plt.title('Average Temperature by Quarter')
plt.xlabel('Quarter')
plt.ylabel('Average Temperature (°C)')
plt.xticks(rotation=45)
plt.show()

"""The first quarter is notably cold, recording the lowest temperatures of the year. The average temperature of -2.794322 underscores the harsh cold weather during this period.

The second quarter sees a temperature increase, indicating favorable weather conditions with an average temperature of 14.479899.

The third quarter experiences a further rise in temperature, averaging 20.561775. The highest temperature of the year is also recorded during this period, emphasizing predominantly clear weather conditions.

However, in the last quarter, there is a rapid temperature decrease. The highest temperature in this quarter is around 18 degrees Celsius, with an average temperature of 2.880978.

## RECCOMMENDATIONS BASED ON TEMPORAL ANALYSES



### First Quarter:
- **Flight Schedules:** Airlines operating in this quarter may need to be prepared for challenging weather conditions, including potential cold temperatures and adverse weather events. Flight delays or cancellations due to snow or icy conditions could be a consideration.
  
- **Dress Code:** Residents should dress warmly, with layers to protect against the cold. Airlines may advise passengers to carry extra layers or blankets, especially for early morning or late-night flights.

### Second Quarter:
- **Flight Schedules:** Generally, this quarter suggests more favorable weather conditions. Airlines may experience fewer disruptions due to weather, leading to more reliable flight schedules.
  
- **Dress Code:** Passengers can expect milder temperatures. While still comfortable, it's advisable to dress in layers as temperatures can vary, especially during early morning or evening flights.

### Third Quarter:
- **Flight Schedules:** This quarter likely offers excellent flying conditions with clear weather. Airlines may experience minimal weather-related disruptions, contributing to reliable flight schedules.
  
- **Dress Code:** Residents can enjoy warmer temperatures. Light and breathable clothing would be suitable, but it's advisable to have a light jacket or sweater for cooler evenings.

### Fourth Quarter:
- **Flight Schedules:** Airlines should be prepared for potential disruptions due to decreasing temperatures, especially in the latter part of the quarter. Flight delays or cancellations due to winter weather conditions may occur.
  
- **Dress Code:** Passengers should dress warmly, with heavier clothing to combat colder temperatures. Airlines may recommend or provide blankets for added comfort during flights.

Adjustments to flight schedules and dress code should be made based on more specific local weather forecasts, but these general considerations can provide a starting point for planning in each quarter.

HUMIDITY ANALYSIS
"""

import matplotlib.pyplot as plt
import seaborn as sns

df['Date/Time'] = pd.to_datetime(df['Date/Time'])

# Set the 'Date/Time' column as the index
df.set_index('Date/Time', inplace=True)

# Plotting the relative humidity over time
plt.figure(figsize=(12, 6))
sns.lineplot(data=df['Rel Hum_%'], color='green')
plt.title('Relative Humidity Over Time')
plt.xlabel('Date/Time')
plt.ylabel('Relative Humidity (%)')
plt.grid(True)
plt.show()

# Analyzing variations in relative humidity
plt.figure(figsize=(12, 6))
sns.boxplot(x=df.index.month, y=df['Rel Hum_%'])
plt.title('Monthly Variations in Relative Humidity')
plt.xlabel('Month')
plt.ylabel('Relative Humidity (%)')
plt.show()

"""In January, relative humidity ranges from a moderate 40% to 90%, with the majority of readings falling between 58% and 75%. February exhibits a similar pattern, ranging from 35% to 92%, with most readings aligning with those observed in January. March shows a wider range, from 18% to 100%, with most readings concentrated between 55% and 80%.

April sees humidity levels between 20% and 90%, with the bulk of readings falling in the 40% to 75% range. May experiences a range of 18% to 90%, with the majority in the 50% to 80% range. June brings higher humidity around 90%, with readings primarily between 45% and 70%. July mirrors June, occasionally exceeding 100%.

In August, relative humidity varies from 35% to 100%, with the majority falling between 58% and 82%. September records peak readings of 22% to 100%, with most readings around 60% to 85%. October features a range of 35% to 100%, with the majority in the 60% to 80% range.

November sees readings between 30% and 90%, with most falling between 60% and 75%. December's readings range from 50% to 98%, with the majority in the 70% to 85% range.

##Brief Highlights:

January and February: Moderate humidity levels indicate relatively comfortable conditions.


March: Wider range suggests variability, with potential for both dry and humid periods.


June and July: Higher humidity, occasionally exceeding 100%, indicating potentially muggy conditions.


August: Variation in humidity with readings mostly in a moderate range.


September: Peak readings suggest a potential for humid conditions.


November: Moderate humidity levels, indicating relatively comfortable conditions.


December: Humidity remains moderate, suggesting comfortable weather for the month.

##CORRELATION ANALYSIS
"""

import matplotlib.pyplot as plt
import seaborn as sns


df['Date/Time'] = pd.to_datetime(df['Date/Time'])

# Set the 'Date/Time' column as the index
df.set_index('Date/Time', inplace=True)

# Calculate correlation matrix
correlation_matrix = df[['Rel Hum_%', 'Temp_C', 'Dew Point Temp_C', 'Wind Speed_km/h', 'Visibility_km', 'Press_kPa']].corr()

# Plotting a heatmap for better visualization
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Matrix')
plt.show()

"""There is a negative correlation of -0.63 between relative humidity and visibility.

Interpretation: A negative correlation indicates that as relative humidity increases, visibility tends to decrease. This suggests that higher humidity levels may be associated with reduced visibility, possibly due to the presence of moisture or fog in the air.

There is a correlation of 0.93 between temperature and dew point temperature.

Interpretation: A strong positive correlation of 0.93 suggests that as temperature increases, the dew point temperature also tends to increase. This indicates a close relationship between the two variables, implying that they rise and fall together. High correlation implies that changes in temperature are closely mirrored by changes in dew point temperature.

There is a weak negative correlation of -0.23 between pressure and relative humidity.

Interpretation: A weak negative correlation indicates that as pressure increases, relative humidity tends to decrease slightly. This suggests a subtle inverse relationship between pressure and humidity. However, the correlation is weak, and other factors may have a more dominant influence on humidity levels.

There is a negative correlation of -0.24 between temperature and pressure.

Interpretation: A negative correlation of -0.24 suggests that as temperature increases, pressure tends to decrease slightly. This could be indicative of weather patterns where higher temperatures are associated with lower atmospheric pressure.

There is a negative correlation of -0.32 between dew point temperature and pressure.

Interpretation: A negative correlation of -0.32 implies that as pressure increases, dew point temperature tends to decrease. This relationship suggests that higher atmospheric pressure may be associated with lower dew point temperatures.
There is a negative correlation of -0.36 between wind speed and pressure.

Interpretation: A negative correlation of -0.36 indicates that as wind speed increases, atmospheric pressure tends to decrease. This could be indicative of weather conditions where higher wind speeds are associated with lower pressure.

There is a positive correlation of 0.23 between visibility and pressure.

Interpretation: A positive correlation of 0.23 suggests that as pressure increases, visibility also tends to increase. This implies that higher atmospheric pressure may be associated with clearer visibility, possibly due to the absence of certain weather phenomena like fog or precipitation.

### CONCLUSION
Understanding these correlations helps in predicting and understanding weather patterns. For example, a strong positive correlation between temperature and dew point temperature suggests that when it gets warmer, the air can hold more moisture. Negative correlations with pressure indicate potential connections between atmospheric conditions, temperature, and visibility. These insights contribute to a better understanding of how different weather variables influence each other.

## WIND SPEED
"""

import matplotlib.pyplot as plt
import seaborn as sns

df['Date/Time'] = pd.to_datetime(df['Date/Time'])

# Set the 'Date/Time' column as the index
df.set_index('Date/Time', inplace=True)

# Plotting the distribution of wind speeds
plt.figure(figsize=(12, 6))
sns.histplot(df['Wind Speed_km/h'], bins=30, kde=True, color='skyblue')
plt.title('Distribution of Wind Speeds')
plt.xlabel('Wind Speed (km/h)')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()

# Identify periods of high wind activity
high_wind_threshold = 70
high_wind_periods = df[df['Wind Speed_km/h'] > high_wind_threshold]

# Display identified periods of high wind activity
print("Periods of High Wind Activity:")
print(high_wind_periods)

df.describe()

import matplotlib.pyplot as plt
import seaborn as sns

df['Date/Time'] = pd.to_datetime(df['Date/Time'])

# Set the 'Date/Time' column as the index
df.set_index('Date/Time', inplace=True)

# Plotting the wind speed over time
plt.figure(figsize=(12, 6))
sns.lineplot(data=df['Wind Speed_km/h'], color='blue')
plt.title('Wind Speed Over Time')
plt.xlabel('Date/Time')
plt.ylabel('Wind Speed (km/h)')
plt.grid(True)
plt.show()

# Set the threshold for high wind speed
high_wind_threshold = 75

# Identify periods with high wind speed
high_wind_periods = df[df['Wind Speed_km/h'] > high_wind_threshold]

# Plotting with markers for high wind speed periods
plt.figure(figsize=(12, 6))
sns.lineplot(data=df['Wind Speed_km/h'], color='blue', label='Wind Speed')
sns.scatterplot(x=high_wind_periods.index, y=high_wind_periods['Wind Speed_km/h'], color='red', label='High Wind Speed')
plt.title('Wind Speed Over Time with High Wind Speed Periods')
plt.xlabel('Date/Time')
plt.ylabel('Wind Speed (km/h)')
plt.legend()
plt.grid(True)
plt.show()

"""VISIBILITY ANALYSIS"""

import matplotlib.pyplot as plt
import seaborn as sns

df['Date/Time'] = pd.to_datetime(df['Date/Time'])

# Set the 'Date/Time' column as the index
df.set_index('Date/Time', inplace=True)

# Plotting the variations in visibility over time
plt.figure(figsize=(12, 6))
sns.lineplot(data=df['Visibility_km'], color='orange')
plt.title('Visibility Over Time')
plt.xlabel('Date/Time')
plt.ylabel('Visibility (km)')
plt.grid(True)
plt.show()

# Analyzing descriptive statistics for visibility
visibility_stats = df['Visibility_km'].describe()
print("Descriptive Statistics for Visibility:")
print(visibility_stats)

# Plotting a box plot to visualize the distribution of visibility
plt.figure(figsize=(8, 6))
sns.boxplot(x=df.index.month, y=df['Visibility_km'])
plt.title('Monthly Variations in Visibility')
plt.xlabel('Month')
plt.ylabel('Visibility (km)')
plt.show()

df['Date/Time'] = pd.to_datetime(df['Date/Time'])

# Set the 'Date/Time' column as the index
df.set_index('Date/Time', inplace=True)

# Extract the month from the index
df['Month'] = df.index.month

# Calculate the mean visibility for each month
mean_visibility_by_month = df.groupby('Month')['Visibility_km'].mean()

# Print the mean visibility for each month
print("Mean Visibility for Each Month:")
print(mean_visibility_by_month)

"""The mean visibility values for each month provide insights into the overall visibility conditions throughout the year. Here's an easy explanation of the visibility patterns across the months:

1. **January (Month 1):** With a mean visibility of 22.1 km, January starts the year with relatively clear visibility, suggesting good visibility conditions for outdoor activities and transportation.

2. **February (Month 2):** Visibility improves slightly in February, reaching an average of 25.18 km. This increase may be indicative of clearer atmospheric conditions compared to January.

3. **March (Month 3):** March sees a further improvement in visibility, with an average of 26.18 km. Clearer skies and improved atmospheric conditions contribute to better visibility during this month.

4. **April (Month 4):** Visibility takes a significant jump in April, reaching 31.78 km. This indicates excellent visibility, making April a month with generally clear atmospheric conditions.

5. **May (Month 5):** Although there is a slight decrease compared to April, May maintains good visibility with an average of 29.42 km. Outdoor visibility remains favorable during this month.

6. **June (Month 6):** June experiences a slight increase in visibility, reaching an average of 32.10 km. The summer season may contribute to these improved visibility conditions.

7. **July (Month 7):** July continues the trend of increasing visibility, with an average of 33.66 km. This suggests excellent visibility during the mid-summer period.

8. **August (Month 8):** August sees a slight decrease in visibility compared to July, averaging 30.19 km. Despite the decrease, visibility remains relatively high, indicating generally clear conditions.

9. **September (Month 9):** September maintains good visibility, with an average of 30.60 km. The transition from summer to fall still provides favorable atmospheric conditions.

10. **October (Month 10):** Visibility experiences a decrease in October, averaging 25.11 km. While slightly lower, visibility remains at a reasonable level for most activities.

11. **November (Month 11):** November sees a slight increase in visibility compared to October, averaging 26.08 km. Fall weather conditions contribute to these visibility patterns.

12. **December (Month 12):** December experiences the lowest visibility of the year, with an average of 19.73 km. Winter weather conditions, including potential fog or precipitation, may contribute to reduced visibility.

In summary, the visibility across the year generally follows a pattern of improvement from the winter months towards the summer months, with variations influenced by seasonal weather conditions.
"""

import matplotlib.pyplot as plt
import seaborn as sns

df['Date/Time'] = pd.to_datetime(df['Date/Time'])

# Set the 'Date/Time' column as the index
df.set_index('Date/Time', inplace=True)

# Define the threshold for low visibility
low_visibility_threshold = 5

# Identify periods with low visibility
low_visibility_periods = df[df['Visibility_km'] < low_visibility_threshold]

# Plotting the entire visibility data
plt.figure(figsize=(12, 6))
sns.lineplot(data=df['Visibility_km'], color='blue', label='Visibility')

# Highlighting periods of low visibility
sns.scatterplot(x=low_visibility_periods.index, y=low_visibility_periods['Visibility_km'], color='red', label='Low Visibility')

plt.title('Visibility Over Time with Periods of Low Visibility')
plt.xlabel('Date/Time')
plt.ylabel('Visibility (km)')
plt.legend()
plt.grid(True)
plt.show()

"""During periods of low visibility depicted in the graph, lifestyle adjustments become necessary to navigate the challenges presented by limited sight. Commuting and transportation may be disrupted, leading to cautious driving and altered routes. Outdoor activities and events might be postponed or canceled, prompting individuals to seek indoor alternatives for recreation. Businesses relying on visibility, such as restaurants and cafes, may experience fluctuations in patronage. The aviation industry may face delays, impacting travel plans. Overall, safety precautions become paramount, emphasizing the need for well-lit spaces and visibility aids. These adjustments showcase the adaptability of individuals in ensuring safety and maintaining a semblance of normalcy during adverse weather conditions.

PRESSURE ANALYSIS
"""

import matplotlib.pyplot as plt
import seaborn as sns

df['Date/Time'] = pd.to_datetime(df['Date/Time'])

# Set the 'Date/Time' column as the index
df.set_index('Date/Time', inplace=True)

# Plotting changes in atmospheric pressure over time
plt.figure(figsize=(12, 6))
sns.lineplot(data=df['Press_kPa'], color='purple')
plt.title('Atmospheric Pressure Over Time')
plt.xlabel('Date/Time')
plt.ylabel('Atmospheric Pressure (kPa)')
plt.grid(True)
plt.show()


# Plotting a box plot to visualize the distribution of atmospheric pressure
plt.figure(figsize=(8, 6))
sns.boxplot(x=df.index.month, y=df['Press_kPa'])
plt.title('Monthly Variations in Atmospheric Pressure')
plt.xlabel('Month')
plt.ylabel('Atmospheric Pressure (kPa)')
plt.show()

"""Extremely low atmospheric pressure is observed in January and February, with the lowest pressure recorded in December. Following February, there is an increase in atmospheric pressure, with a slight further increase in April. Another notable increase occurs from May through September, followed by a rapid decrease. Subsequently, there is a slow increase in atmospheric pressure until December.

**Inference:**
The observed pattern suggests a cyclical nature in atmospheric pressure fluctuations throughout the year. The initial low pressures in January and February may be associated with winter weather conditions. The subsequent increase in pressure from February to April might indicate a transition to more stable atmospheric conditions. The notable rise from May to September aligns with the typical progression of atmospheric pressure during the warmer months. The rapid decrease post-September could be linked to changing weather patterns as fall approaches. The slow increase from October to December may reflect a stabilization of atmospheric conditions as the year concludes. Understanding these pressure variations contributes to broader insights into seasonal weather changes.
"""

import matplotlib.pyplot as plt
import seaborn as sns


df['Date/Time'] = pd.to_datetime(df['Date/Time'])

# Set the 'Date/Time' column as the index
df.set_index('Date/Time', inplace=True)

# Define a threshold for low atmospheric pressure
low_pressure_threshold = 1000

# Identify periods with low atmospheric pressure
low_pressure_periods = df[df['Press_kPa'] < low_pressure_threshold]

# Plotting changes in atmospheric pressure over time
plt.figure(figsize=(12, 6))
sns.lineplot(data=df['Press_kPa'], color='green', label='Atmospheric Pressure')

# Highlighting periods of low atmospheric pressure
sns.scatterplot(x=low_pressure_periods.index, y=low_pressure_periods['Press_kPa'], color='red', label='Low Pressure')

plt.title('Atmospheric Pressure Over Time with Periods of Low Pressure')
plt.xlabel('Date/Time')
plt.ylabel('Atmospheric Pressure (kPa)')
plt.legend()
plt.grid(True)
plt.show()

# Print descriptive statistics for low-pressure periods
low_pressure_stats = low_pressure_periods['Press_kPa'].describe()
print("Descriptive Statistics for Low Pressure Periods:")
print(low_pressure_stats)

# Print specific dates or times associated with low pressure
print("Dates and Times with Low Atmospheric Pressure:")
print(low_pressure_periods.index)

import matplotlib.pyplot as plt
import seaborn as sns

df['Date/Time'] = pd.to_datetime(df['Date/Time'])

# Set the 'Date/Time' column as the index
df.set_index('Date/Time', inplace=True)

# Define a threshold for low atmospheric pressure
low_pressure_threshold = 1000  # Adjust as needed based on your definition of low pressure

# Identify periods with low atmospheric pressure
low_pressure_periods = df[df['Press_kPa'] < low_pressure_threshold]

# Plotting changes in atmospheric pressure over time with highlighted periods of low pressure
plt.figure(figsize=(12, 6))
sns.lineplot(data=df['Press_kPa'], color='purple', label='Atmospheric Pressure')
sns.scatterplot(x=low_pressure_periods.index, y=low_pressure_periods['Press_kPa'], color='red', label='Low Pressure')
plt.title('Atmospheric Pressure Over Time with Periods of Low Pressure')
plt.xlabel('Date/Time')
plt.ylabel('Atmospheric Pressure (kPa)')
plt.legend()
plt.grid(True)
plt.show()

# Plotting a box plot to visualize the distribution of atmospheric pressure with highlighted periods of low pressure
plt.figure(figsize=(8, 6))
sns.boxplot(x=df.index.month, y=df['Press_kPa'])
sns.scatterplot(x=low_pressure_periods.index.month, y=low_pressure_periods['Press_kPa'], color='red', label='Low Pressure')
plt.title('Monthly Variations in Atmospheric Pressure with Highlighted Periods of Low Pressure')
plt.xlabel('Month')
plt.ylabel('Atmospheric Pressure (kPa)')
plt.legend()
plt.show()

"""## DISTRIBUTION OF WEATHER CONDITIONS"""

import matplotlib.pyplot as plt
import seaborn as sns

# Count occurrences of different weather conditions
weather_counts = df['Weather'].value_counts()

# Plot a bar chart to visualize the distribution of weather conditions
plt.figure(figsize=(10, 6))
sns.barplot(x=weather_counts.index, y=weather_counts.values, palette='viridis')
plt.title('Distribution of Weather Conditions')
plt.xlabel('Weather Condition')
plt.ylabel('Count')
plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability
plt.tight_layout()
plt.show()

# Print the counts of each weather condition
print("Occurrences of Different Weather Conditions:")
print(weather_counts)

"""The pattern shown above, depicting the frequency of various weather conditions, is crucial for planning and adapting to the diverse climate experiences in the region. The prominence of mainly clear and mostly cloudy conditions suggests periods of relatively stable weather, providing opportunities for outdoor activities and travel. The occurrences of precipitation-related conditions like rain, snow, and drizzle necessitate preparedness for potential disruptions in transportation and daily routines during inclement weather.

Fog occurrences, particularly when combined with other weather elements, highlight instances of reduced visibility, emphasizing the need for caution and adjusted travel plans during such periods. Rare events like thunderstorms and freezing fog indicate extreme conditions that may have specific safety implications, requiring heightened awareness and preparedness.

Understanding the frequency and distribution of these weather conditions enables individuals, businesses, and local authorities to implement effective strategies for managing various scenarios. It informs decisions related to transportation, outdoor events, and overall safety, contributing to a more resilient and adaptive approach to the region's diverse climate experiences.
"""

import matplotlib.pyplot as plt
import seaborn as sns

df['Date/Time'] = pd.to_datetime(df['Date/Time'])

# Set the 'Date/Time' column as the index
df.set_index('Date/Time', inplace=True)

# Resample data to daily, monthly, and seasonal averages
daily_avg = df['Temp_C'].resample('D').mean()
monthly_avg = df['Temp_C'].resample('M').mean()
seasonal_avg = df['Temp_C'].resample('Q-DEC').mean()

# Plotting daily, monthly, and seasonal trends
plt.figure(figsize=(16, 10))

# Daily trend
plt.subplot(3, 1, 1)
sns.lineplot(data=daily_avg, color='blue')
plt.title('Daily Average Temperature Over Time')
plt.xlabel('Date')
plt.ylabel('Temperature (°C)')

# Monthly trend
plt.subplot(3, 1, 2)
sns.lineplot(data=monthly_avg, color='green')
plt.title('Monthly Average Temperature Over Time')
plt.xlabel('Date')
plt.ylabel('Temperature (°C)')

# Seasonal trend
plt.subplot(3, 1, 3)
sns.lineplot(data=seasonal_avg, color='orange')
plt.title('Seasonal Average Temperature Over Time')
plt.xlabel('Date')
plt.ylabel('Temperature (°C)')

plt.tight_layout()
plt.show()

"""Identifying recuring patterns and trends"""

from statsmodels.tsa.seasonal import seasonal_decompose

df['Date/Time'] = pd.to_datetime(df['Date/Time'])

# Set the 'Date/Time' column as the index
df.set_index('Date/Time', inplace=True)

# Resample data to daily averages
daily_avg = df['Temp_C'].resample('D').mean()

# Decompose the time series
result = seasonal_decompose(daily_avg, model='additive')

# Plot the decomposed components with improved x-axis labels
plt.figure(figsize=(12, 8))

# Original time series
plt.subplot(4, 1, 1)
plt.plot(result.observed, label='Observed', color='blue')
plt.title('Original Time Series')
plt.xlabel('Date')
plt.ylabel('Temperature (°C)')
plt.legend()

# Trend component
plt.subplot(4, 1, 2)
plt.plot(result.trend, label='Trend', color='orange')
plt.title('Trend Component')
plt.xlabel('Date')
plt.ylabel('Temperature (°C)')
plt.legend()

# Seasonal component
plt.subplot(4, 1, 3)
plt.plot(result.seasonal, label='Seasonal', color='green')
plt.title('Seasonal Component')
plt.xlabel('Date')
plt.ylabel('Temperature (°C)')
plt.legend()

# Residual component
plt.subplot(4, 1, 4)
plt.plot(result.resid, label='Residual', color='red')
plt.title('Residual Component')
plt.xlabel('Date')
plt.ylabel('Temperature (°C)')
plt.legend()

plt.tight_layout()
plt.suptitle('Seasonal Decomposition of Daily Average Temperature', y=1.02)
plt.show()

from statsmodels.graphics.tsaplots import plot_acf

# Plot autocorrelation function
plot_acf(daily_avg, lags=30)
plt.title('Autocorrelation of Daily Average Temperature')
plt.show()

"""The autocorrelation graph for daily average temperature, starting at 1 and gradually decreasing to 0.50, suggests a pattern of decreasing correlation as the time lag increases. Here's how to interpret this:

1. **High Initial Autocorrelation (Near 1):**
   - The high autocorrelation at lag 1 indicates a strong positive relationship between the daily average temperature on consecutive days. In other words, today's temperature is highly correlated with yesterday's temperature.

2. **Gradual Decrease in Autocorrelation:**
   - As the time lag increases, the autocorrelation gradually decreases. This decreasing pattern is often referred to as autocorrelation decay.
   - A decrease in autocorrelation over time suggests that the influence of past temperatures on the current temperature diminishes as the time lag increases.

3. **Autocorrelation of 0.50:**
   - An autocorrelation of 0.50 at a certain lag indicates a moderate positive relationship between the daily average temperature at that lag and the current temperature. While it's not as strong as the initial autocorrelation, it still suggests some persistence or correlation between temperatures at different time points.

4. **Implications for Weather Patterns:**
   - The autocorrelation pattern observed may indicate a form of seasonality or cyclicality in the daily average temperature data.
   - It implies that there is some predictability in the temperature patterns based on historical observations, although this predictability diminishes as we look further back in time.

"""

# Calculate rolling mean and rolling standard deviation
rolling_mean = daily_avg.rolling(window=30, center=True).mean()
rolling_std = daily_avg.rolling(window=30, center=True).std()

# Plot original time series and rolling statistics
plt.figure(figsize=(12, 6))
plt.plot(daily_avg, label='Original Time Series', color='blue')
plt.plot(rolling_mean, label='Rolling Mean', color='red')
plt.plot(rolling_std, label='Rolling Std Dev', color='green')
plt.title('Daily Average Temperature with Rolling Statistics')
plt.xlabel('Date')
plt.ylabel('Temperature (°C)')
plt.legend()
plt.show()

"""Develop machine learning models to predict specific weather conditions or patterns. For instance, you could build a model to predict rainy days based on other weather features.

INVESTIGATING TRANSITIONS BETWEEN WEATHER CONDITIONS
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df['Date/Time'] = pd.to_datetime(df['Date/Time'])

# Set the 'Date/Time' column as the index
df.set_index('Date/Time', inplace=True)

# Create a new column 'Next_Weather' to represent the next day's weather
df['Next_Weather'] = df['Weather'].shift(-1)

# Drop the last row since there's no 'next' day for it
df = df.dropna()

# Create a transition matrix
transition_matrix = pd.crosstab(df['Weather'], df['Next_Weather'], normalize='index')

# Plot the transition matrix as a heatmap with increased figure size and adjusted aspect ratio
plt.figure(figsize=(30, 20))
sns.heatmap(transition_matrix, cmap='Blues', annot=True, fmt=".2f", cbar_kws={'label': 'Transition Probability'},
            linewidths=.5, square=True, annot_kws={"size": 10})
plt.title('Weather Condition Transition Matrix')
plt.xlabel('Next Weather Condition')
plt.ylabel('Current Weather Condition')
plt.tight_layout()
plt.show()

df['Date/Time'] = pd.to_datetime(df['Date/Time'])

# Set the 'Date/Time' column as the index
df.set_index('Date/Time', inplace=True)

# Define the date ranges for specific events or holidays
# For example, let's consider New Year's Day and Independence Day
new_years_day_range = ('2012-01-01', '2012-01-01')
independence_day_range = ('2012-07-04', '2012-07-04')

# Filter the dataframe for the specified date ranges
new_years_day_weather = df.loc[new_years_day_range[0]:new_years_day_range[1]]
independence_day_weather = df.loc[independence_day_range[0]:independence_day_range[1]]

# Print summary statistics or perform additional analysis on the filtered data
print("Weather during New Year's Day:")
print(new_years_day_weather['Weather'].value_counts())

print("\nWeather during Independence Day:")
print(independence_day_weather['Weather'].value_counts())

"""CLUSTERING ANALYSIS"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA


df['Date/Time'] = pd.to_datetime(df['Date/Time'])

# Set the 'Date/Time' column as the index
df.set_index('Date/Time', inplace=True)

# Select relevant weather features for clustering
weather_features = ['Temp_C', 'Dew Point Temp_C', 'Rel Hum_%', 'Wind Speed_km/h', 'Visibility_km', 'Press_kPa']

# Standardize the features
scaler = StandardScaler()
scaled_data = scaler.fit_transform(df[weather_features])

# Determine the optimal number of clusters using the Elbow Method
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)
    kmeans.fit(scaled_data)
    wcss.append(kmeans.inertia_)

# Plot the Elbow Method
plt.plot(range(1, 11), wcss)
plt.title('Elbow Method for Optimal k')
plt.xlabel('Number of Clusters')
plt.ylabel('WCSS (Within-Cluster Sum of Squares)')
plt.show()

# Based on the Elbow Method, choose the optimal number of clusters (k)
optimal_k = 3

# Apply k-means clustering
kmeans = KMeans(n_clusters=optimal_k, init='k-means++', random_state=42)
df['Cluster'] = kmeans.fit_predict(scaled_data)

# Reduce dimensionality for visualization using PCA
pca = PCA(n_components=2)
pca_result = pca.fit_transform(scaled_data)
df['PCA1'] = pca_result[:, 0]
df['PCA2'] = pca_result[:, 1]

# Plot the clusters in 2D PCA space
plt.figure(figsize=(10, 8))
sns.scatterplot(x='PCA1', y='PCA2', hue='Cluster', data=df, palette='viridis', legend='full', alpha=0.7)
plt.title('Weather Pattern Clusters in 2D PCA Space')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.show()

# Apply k-means clustering
kmeans = KMeans(n_clusters=optimal_k, init='k-means++', random_state=42)
df['Cluster'] = kmeans.fit_predict(scaled_data)


df['Date/Time'] = pd.to_datetime(df['Date/Time'])

# Set the 'Date/Time' column as the index
df.set_index('Date/Time', inplace=True)

# Group data by 'Cluster' and calculate the average values for each cluster
cluster_means = df.groupby('Cluster')[weather_features].mean()

# Print the average values for each cluster
print("Average Values for Each Cluster:")
print(cluster_means)

# Visualize temporal patterns for each cluster
plt.figure(figsize=(16, 10))
for cluster in range(optimal_k):  # Assuming 'optimal_k' is the number of clusters
    cluster_data = df[df['Cluster'] == cluster]
    plt.plot(cluster_data.index, cluster_data['Temp_C'], label=f'Cluster {cluster}')

plt.title('Temporal Patterns for Each Cluster')
plt.xlabel('Date')
plt.ylabel('Temperature (°C)')
plt.legend()
plt.show()

"""ML MODEL FOR PREDICTION"""

import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

def train_weather_model(df, features, target):


    # Drop rows with missing values in the selected features and target
    df = df.dropna(subset=features + [target])

    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(
        df[features], df[target], test_size=0.2, random_state=42
    )

    # Initialize and train a machine learning model (Random Forest Classifier as an example)
    model = RandomForestClassifier(random_state=42)
    model.fit(X_train, y_train)

    # Make predictions on the test set
    predictions = model.predict(X_test)

    # Evaluate the model (optional)
    accuracy = accuracy_score(y_test, predictions)
    print(f"Model Accuracy: {accuracy}")

    return model

def predict_weather_conditions(model, input_data):


    # Make predictions on the input data
    predictions = model.predict(input_data)

    return predictions

def get_user_input_and_predict(model):


    # Get input parameters from the user
    temp_c = float(input("Enter Temperature in Celsius: "))
    dew_point_temp_c = float(input("Enter Dew Point Temperature in Celsius: "))
    rel_humidity = int(input("Enter Relative Humidity (%): "))
    wind_speed_kmh = int(input("Enter Wind Speed in km/h: "))
    visibility_km = float(input("Enter Visibility in km: "))
    press_kpa = float(input("Enter Atmospheric Pressure in kPa: "))

    # Create a DataFrame with user input
    input_data = pd.DataFrame({
        'Temp_C': [temp_c],
        'Dew Point Temp_C': [dew_point_temp_c],
        'Rel Hum_%': [rel_humidity],
        'Wind Speed_km/h': [wind_speed_kmh],
        'Visibility_km': [visibility_km],
        'Press_kPa': [press_kpa],
    })

    # Make predictions
    predicted_weather = predict_weather_conditions(model, input_data)

    return predicted_weather



features = ['Temp_C', 'Dew Point Temp_C', 'Rel Hum_%', 'Wind Speed_km/h', 'Visibility_km', 'Press_kPa']

# Train the model
trained_model = train_weather_model(df, features, target_column)

# Get user input and make predictions
predicted_weather = get_user_input_and_predict(trained_model)

print("Predicted Weather Condition:", predicted_weather[0])

!pip install xgboost

"""# **General Inference:**

The weather analysis project reveals dynamic patterns and trends throughout the year, offering valuable insights into temperature variations, humidity levels, atmospheric pressure, visibility, and their interdependencies. These findings contribute to a comprehensive understanding of the region's climate, enabling informed decision-making for various sectors.

**Key Findings:**
1. **Temperature Trends:**
   - The year begins with extremely cold temperatures in the first quarter, gradually transitioning to milder conditions in the second quarter.
   - The third quarter experiences a significant temperature increase, indicative of predominantly clear weather.
   - A rapid decrease in temperature characterizes the last quarter, returning to colder conditions.

2. **Humidity Observations:**
   - Humidity levels exhibit variability across the months, with notable peaks in June and July.
   - August records a range of humidity levels, suggesting diverse atmospheric conditions.
   - The latter months of the year maintain moderate humidity, contributing to comfortable weather.

3. **Atmospheric Pressure Dynamics:**
   - Observations indicate cyclical fluctuations in atmospheric pressure throughout the year.
   - Low pressures in January and February give way to a steady increase until April, with another notable rise from May to September.
   - Post-September sees a rapid decrease in pressure, followed by a gradual increase leading to December.

4. **Visibility Patterns:**
   - Visibility follows a generally improving trend from winter to summer, with December showing the lowest visibility.
   - Outdoor activities and transportation are influenced by visibility conditions, with lifestyle adjustments required during periods of low visibility.

5. **Correlation Analysis:**
   - Strong correlations between temperature and dew point temperature suggest synchronous changes in these variables.
   - Negative correlations with pressure hint at potential weather relationships, with higher temperatures linked to lower pressure.
   - Understanding these correlations enhances the prediction and analysis of weather patterns.

**Recommendations:**
   - **Flight Schedules:** Planes operating in the first and last quarters should be prepared for potential disruptions due to cold temperatures and adverse weather events. The second and third quarters generally offer more favorable conditions.
   - **Dress Code:** Residents should adapt their clothing choices based on temperature trends. Layered clothing is advisable in colder months, while lighter attire is suitable during warmer periods.

**Conclusion:**
This weather analysis project provides a robust foundation for informed decision-making related to various aspects of daily life, from travel planning to dressing appropriately for weather conditions. The cyclical nature of temperature, humidity, and atmospheric pressure, along with their interdependencies, contributes to a nuanced understanding of the region's climate. The findings empower individuals, businesses, and local authorities to proactively adapt and plan for diverse weather scenarios, ultimately enhancing resilience and preparedness.
"""
